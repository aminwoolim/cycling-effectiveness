{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# 03 — Machine Learning (Regression & Classification)\n",
    "- feature prep & scaling\n",
    "- TF models\n",
    "- evaluation (MAE/R², confusion matrix, ROC AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, classification_report\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "df = pd.read_csv(\"/Users/amlim/cycling-effectiveness/data/cleaned_cycling.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_numeric_column(df, cols):\n",
    "    \"\"\"\n",
    "    Cleans numeric columns in a DataFrame:\n",
    "    - Removes commas\n",
    "    - Replaces '--' with NaN\n",
    "    - Converts to float\n",
    "    \"\"\"\n",
    "    if isinstance(cols, str):\n",
    "        cols = [cols]   # allow single column name\n",
    "    \n",
    "    for col in cols:\n",
    "        df[col] = (\n",
    "            df[col].astype(str)                # ensure string\n",
    "                  .str.replace(\",\", \"\", regex=False)  # remove commas\n",
    "                  .replace(\"--\", np.nan)       # replace placeholder\n",
    "                  .replace(\"nan\", np.nan)      # just in case\n",
    "                  .astype(float)               # convert to float\n",
    "        )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = clean_numeric_column(df, [\"Calories\", \"Avg HR\", \"Avg Speed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"Session_Type\" not in df.columns and \"Activity Type\" in df.columns:\n",
    "    def classify_session(activity):\n",
    "        return \"Indoors\" if activity in [\"indoor_cycling\", \"virtual_ride\"] else \"Outdoors\"\n",
    "    df[\"Session Type\"] = df[\"Activity Type\"].apply(classify_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"Training Stress Score®\" in df.columns and \"Training_Stress_Score\" not in df.columns:\n",
    "    df.rename(columns={\"Training Stress Score®\": \"Training Stress Score\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## ML and Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"Duration_min\" not in df.columns and \"Duration\" in df.columns:\n",
    "    def parse_duration(val):\n",
    "        try:\n",
    "            parts = val.split(\":\")\n",
    "            if len(parts) == 2:\n",
    "                val = \"00:\" + val\n",
    "            return pd.to_timedelta(val).total_seconds() / 60\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "    df[\"Duration_min\"] = df[\"Duration\"].astype(str).apply(parse_duration)\n",
    "\n",
    "df = df.dropna(subset=[\"Duration_min\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"Calories_per_min\" not in df.columns:\n",
    "    df[\"Calories_per_min\"] = df[\"Calories\"] / df[\"Duration_min\"]\n",
    "if \"Training_Stress_Score\" in df.columns and \"TSS_per_min\" not in df.columns:\n",
    "    df[\"TSS_per_min\"] = df[\"Training_Stress_Score\"] / df[\"Duration_min\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"High_Effectiveness\" not in df.columns:\n",
    "    thr = df[\"Calories_per_min\"].quantile(0.75)\n",
    "    df[\"High_Effectiveness\"] = (df[\"Calories_per_min\"] >= thr).astype(int)\n",
    "if \"Session_Type\" in df.columns and df[\"Session_Type\"].dtype == \"object\":\n",
    "    df = pd.get_dummies(df, columns=[\"Session_Type\"], drop_first=True)\n",
    "if \"Time_of_Day\" in df.columns and df[\"Time_of_Day\"].dtype == \"object\":\n",
    "    df = pd.get_dummies(df, columns=[\"Time_of_Day\"], drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# If you haven't already in a prior cell, ensure df exists:\n",
    "# df = pd.read_csv(\"../data/cleaned_cycling.csv\")\n",
    "\n",
    "# If you did one-hot encoding in earlier cells on df, great.\n",
    "# Now create a modeling copy:\n",
    "df_ml = df.copy()\n",
    "\n",
    "# --- Build feature list safely from what actually exists ---\n",
    "num_feats = [\n",
    "    \"Duration_min\", \"Distance\", \"Avg HR\", \"Avg Speed\",\n",
    "    \"Avg Bike Cadence\", \"Max HR\", \"Max Speed\",\n",
    "    \"Power\", \"Max Power\", \"Max Avg Power (20 min)\",\n",
    "    \"Elev Gain\", \"Elev Loss\", \"Training_Stress_Score\"\n",
    "]\n",
    "num_feats = [c for c in num_feats if c in df_ml.columns]\n",
    "\n",
    "# One-hot (dummy) columns that may exist (Afternoon is implicit baseline)\n",
    "dummy_feats = [\n",
    "    \"Session_Type_Outdoors\",\n",
    "    \"Time_of_Day_Morning\",\n",
    "    \"Time_of_Day_Evening\"\n",
    "]\n",
    "dummy_feats = [c for c in dummy_feats if c in df_ml.columns]\n",
    "\n",
    "X_cols = num_feats + dummy_feats\n",
    "print(\"Using features:\", X_cols)\n",
    "\n",
    "# Targets\n",
    "if \"Calories_per_min\" not in df_ml.columns:\n",
    "    raise ValueError(\"Calories_per_min not found. Compute it before this step.\")\n",
    "y_reg = df_ml[\"Calories_per_min\"]\n",
    "\n",
    "if \"High_Effectiveness\" not in df_ml.columns:\n",
    "    # create label here if your cleaned file doesn't have it yet\n",
    "    thr = y_reg.quantile(0.75)\n",
    "    df_ml[\"High_Effectiveness\"] = (y_reg >= thr).astype(int)\n",
    "y_clf = df_ml[\"High_Effectiveness\"]\n",
    "\n",
    "# Assemble X and coerce to numeric\n",
    "X = df_ml[X_cols].apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "# Drop rows with any NaNs in features or targets\n",
    "mask = X.notna().all(axis=1) & y_reg.notna() & y_clf.notna()\n",
    "X = X.loc[mask]\n",
    "y_reg = y_reg.loc[mask]\n",
    "y_clf = y_clf.loc[mask]\n",
    "\n",
    "# Train/test splits\n",
    "X_train, X_test, y_train_reg, y_test_reg = train_test_split(\n",
    "    X, y_reg, test_size=0.2, random_state=42\n",
    ")\n",
    "X_train_c, X_test_c, y_train_clf, y_test_clf = train_test_split(\n",
    "    X, y_clf, test_size=0.2, random_state=42, stratify=y_clf\n",
    ")\n",
    "\n",
    "# Scale features\n",
    "scaler_reg = StandardScaler()\n",
    "X_train_s = scaler_reg.fit_transform(X_train)\n",
    "X_test_s  = scaler_reg.transform(X_test)\n",
    "\n",
    "scaler_clf = StandardScaler()\n",
    "X_train_c_s = scaler_clf.fit_transform(X_train_c)\n",
    "X_test_c_s  = scaler_clf.transform(X_test_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "tf.keras.utils.set_random_seed(42)\n",
    "\n",
    "model_reg = Sequential([\n",
    "    Dense(64, activation=\"relu\", input_shape=(X_train_s.shape[1],)),\n",
    "    Dense(32, activation=\"relu\"),\n",
    "    Dense(1)\n",
    "])\n",
    "\n",
    "model_reg.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"mae\"])\n",
    "hist_reg = model_reg.fit(X_train_s, y_train_reg, validation_split=0.2, epochs=100, batch_size=16, verbose=0)\n",
    "\n",
    "# Evaluate\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "y_pred_reg = model_reg.predict(X_test_s).ravel()\n",
    "print(\"Regression — MAE:\", mean_absolute_error(y_test_reg, y_pred_reg))\n",
    "print(\"Regression — R^2:\", r2_score(y_test_reg, y_pred_reg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "tf.keras.utils.set_random_seed(42)\n",
    "\n",
    "model_clf = Sequential([\n",
    "    Dense(64, activation=\"relu\", input_shape=(X_train_c_s.shape[1],)),\n",
    "    Dense(32, activation=\"relu\"),\n",
    "    Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model_clf.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "hist_clf = model_clf.fit(X_train_c_s, y_train_clf, validation_split=0.2, epochs=60, batch_size=16, verbose=0)\n",
    "\n",
    "y_prob = model_clf.predict(X_test_c_s).ravel()\n",
    "y_pred = (y_prob >= 0.5).astype(int)\n",
    "\n",
    "print(classification_report(y_test_clf, y_pred))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_test_clf, y_pred))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_test_clf, y_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "y_pred_baseline = np.full_like(y_test_reg, y_train_reg.mean(), dtype=float)\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "print(\"Baseline MAE:\", mean_absolute_error(y_test_reg, y_pred_baseline))\n",
    "print(\"Baseline R²:\", r2_score(y_test_reg, y_pred_baseline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(y_test_reg, y_test_reg - y_pred_reg, s=12)\n",
    "plt.axhline(0, ls=\"--\"); plt.xlabel(\"Actual\"); plt.ylabel(\"Residuals\"); plt.title(\"Residuals vs Actual\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_reg.save(\"/Users/amlim/cycling-effectiveness/results/model_reg.h5\")\n",
    "model_clf.save(\"/Users/amlim/cycling-effectiveness/results/model_clf.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cycling)",
   "language": "python",
   "name": "cycling"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
